1、rabbitmq如何实现延时消息
ttl可以设置队列的过期时间。固定延时时间
ttl也可以设置消息的过期时间：只有在队列顶部的才会被移除，不在顶部的不会。有局限
用ttl+死信队列完成；延时交换机绑定延迟队列，为延时队列设置死信交换机，死信交换机绑定死信队列，消费者消费死信队列数据
固定延时时间
用延时队列插件：随机延时时间；内部是开启一个定时器，轮询到期的消息到队列


2、rabbitmq有哪些交换机
Direct Exchange（直连交换机）:消息会传送给绑定键与消息的路由键完全匹配的那个队列
Fanout Exchange（扇型交换机）:消息会发送到所有绑定到交换机的队列上。路由键无效
Topic Exchange（主题交换机）:消息发送给匹配到路由键的队列上。可以用通配符
Header Exchenge（头交换机）：需要匹配消息头，一个消息有消息头设置消息头属性（map），header有x-match属性，all全部匹配和any任何一个匹配

3、在一个有事务的方法中，进行mq消息发送，怎么保证事务提交后，才进行消息消费
可以使用TransactionSynchronizationManager，可以再事务提交后做一些事情，比如发短信、websocket

4、rabbitmq 节点类型
单节点运行只有磁盘节点
集群运行：
内存节点：内存节点将全部的队列，交换器，绑定关系，用户，权限，和vhost的元数据信息保存在内存中
磁盘节点：元数据信息存在磁盘上

5、RabiitMQ对集群节点停止顺序有要求么，为什么
应该先关闭内存节点，最后关闭磁盘节点，如果顺序相反，可能会造成消息的丢失。

6、如何避免消息重复投递或重复消费
从应用层面：我们要保证消费端消息幂等
在消息生产时，MQ 内部针对每条生产者发送的消息生成一个 inner-msg-id，作为去重的依据（消息投递失败并重传），避免重复的消息进入队列
在消息消费时，要求消息体中必须要有一个 bizId（对于同一业务全局唯一，如支付 ID、订单 ID、帖子 ID 等）作为去重的依据，避免同一条消息被重复消费

7、如何保证消息不丢失
丢失消息一般分为三种，一种是生产者丢了数据，二是rabbitMQ自己丢了数据，三是消费端丢了数据；
生产者丢失数据：
可以选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，
如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；
如果收到了消息，那么可以提交事务channel.txCommit。
缺点：
但是问题是，RabbitMQ 事务机制是同步的，你提交一个事务之后会阻塞在那儿，采用这种方式基本上吞吐量会下来，因为太耗性能。
// 开启事务
channel.txSelect
try {
  // 这里发送消息
} catch (Exception e) {
  channel.txRollback
// 这里再次重发这条消息
}
// 提交事务
channel.txCommit
方式二：开启confirm模式，在生产者那里设置开启confirm模式，每次写的消息会被分配一个唯一的id，然后写到rabbitmq之中，
会回传一个ack消息，告诉你这个消息ok了，如果rabbitmq没能处理这个消息，会回调一个nack接口，告诉消息失败，此时可以进行重试，
而且你可以结合这个机制知道自己在内存里维护每个消息的id，如果超过一定时间还没接收到这个消息的回调，那么可以进行重发


针对rabbitmq自己丢了数据：
设置消息持久化到磁盘
创建queue的时候将其设置为持久化的，这样可以保证rabbitmq持久化的队列的元数据，但是不会持久化queue里面的数据；
发送消息的时候将消息的deliveryMode设置为2，这样消息就会被设置为持久化方式，此时rabbitmq就会将消息持久化到磁盘上；必须同时保证开启这两个才行；
而且持久化可以根生产的confirm机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算在持久化之前rabbitmq挂了，数据丢了，生产者收不到回调，也会进行消息重发；

消费端丢失数据：
关闭消费端自动ack，改为手动ack，当消息消费完成后再和服务端确认，服务端在删除消息。

7、rabbitmq 保证顺序消费
把同一类型的消息放到一个队列，比如创建事件、处理事件、办结事件类似的，然后消费端取的时候采用分布式锁，一个一个消费
如果生产端不能保证有序，比如并发编辑，也可以用分布式锁。
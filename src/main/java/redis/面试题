1、redis 键过期策略
惰性删除：当访问一个key是才判断是否过期，过期了就删除。节省cpu 对内存不友好
定期删除：定期的在设置了过期键的key中，随机选择一部分，检查是否过期。过期则删除
2、redis 内存淘汰策略
当redis内存不足时，会触发内存淘汰策略，分3类8中
第一类：对设置了过期时间的key进行操作
volatile-lru：当内存不足以容纳新写入数据时，从设置了过期时间的key中使用LRU（最近最少使用）算法进行淘汰；
volatile-lfu：4.0版本新增，当内存不足以容纳新写入数据时，在过期的key中，使用LFU算法进行删除key。
volatile-random：当内存不足以容纳新写入数据时，从设置了过期时间的key中，随机淘汰数据；
volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的key中，根据过期时间进行淘汰，越早过期的优先被淘汰；
第二类：对所有key进行操作
allkeys-lru：当内存不足以容纳新写入数据时，从所有key中使用LRU（最近最少使用）算法进行淘汰
allkeys-lfu：4.0版本新增，当内存不足以容纳新写入数据时，从所有key中使用LFU算法进行淘汰
allkeys-random：当内存不足以容纳新写入数据时，从所有key中随机淘汰数据。
第三类：内存不足时直接拒绝
noeviction：默认策略，当内存不足以容纳新写入数据时，新写入操作会报错。
3、reids hash数据类型的rehash过程,渐进式rehash?
    当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作：
    1、服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 1 ；
    2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令， 并且哈希表的负载因子大于等于 5（避免执行命令期间进行扩容；避免过多内存写入，造成性能低下。） ；

    当哈希表的负载因子小于 0.1 时， 程序自动开始对哈希表执行收缩操作。

    其中哈希表的负载因子可以通过公式计算：
    # 负载因子 = 哈希表已保存节点数量 / 哈希表大小
    load_factor = ht[0].used / ht[0].size

    Redis 对字典的哈希表执行 rehash 的步骤：
    1、为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是ht[0].used 属性的值）：
    1.1、如果执行的是扩展操作，那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n；
    1.2、如果执行的是收缩操作，那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 。
    2、将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面：
    rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。
    3、当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ，
    将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。

    渐进式 rehash：
    扩展或收缩哈希表需要将 ht[0] 里面的所有键值对 rehash 到 ht[1] 里面。
    但是， 这个 rehash 动作并不是一次性、集中式地完成的， 而是分多次、渐进式地完成的。

    原因：
    如果 ht[0] 里只保存着四个键值对， 那么服务器可以在瞬间就将这些键值对全部 rehash 到 ht[1] ；
    但是， 如果哈希表里保存的键值对数量不是四个， 而是四百万、四千万甚至四亿个键值对，
    那么要一次性将这些键值对全部 rehash 到 ht[1] 的话， 庞大的计算量可能会导致服务器在一段时间内停止服务。

    因此， 为了避免 rehash 对服务器性能造成影响， 服务器不是一次性将 ht[0] 里面的所有键值对全部 rehash 到 ht[1] ，
    而是分多次、渐进式地将 ht[0] 里面的键值对慢慢地 rehash 到 ht[1] 。

    以下是哈希表渐进式 rehash 的详细步骤：
    1、为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。
    2、在字典中维持一个索引计数器变量 rehashidx(代表数组索引值) ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。
    3、在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外，
    还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。
    4、随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ，
    这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。

    渐进式 rehash 的好处在于它采取分而治之的方式， 将 rehash 键值对所需的计算工作均滩到对字典的每个添加、删除、查找和更新操作上， 从而避免了集中式 rehash 而带来的庞大计算量。
    在rehash期间进行删除、查找、更新操作会在两个哈希表上进行；新增则只会在ht[1]进行，ht[0]不进行任何添加操作，这一操作保证ht[0]只减不增，最终编程空表


4、redis hash与java hashmap
    redis 数组+单项链表，为了速度采用头插法（单线程不存在链表循环）。
    hashmap 数组+单项链表+红黑树。为了解决头插法在并发下链表循环问题，采用尾插法。
    redis 扩容是渐进式的。hashmap的扩容是一次性的
    redis 可以收缩。hashmap不可以


5、说说redis 线程模型
redis是基于IO多路复用实现的单线程模型。它内部有一个文件事件处理器，他是单线程处理读写、执行命令。
文件事件处理器：多个socket、IO多路复用程序、文件事件分派器、文件事件处理器
// 入口函数
void aeMain(EventLoop eventLoop) {
    while(true) {
    	// 文件事件处理器
    	aeProcessEvents(eventLoop);
    }
}
void aeProcessEvents() {
	// 调用 epoll_wait 函数，等待I/O事件 （IO 多路复用程序）
    int numevents = aeApiPoll(timeval);
    for(int i=0; i< numevents; i++) {
    	// 从队列中取出对应的事件
    	fileEvent = getFromEventQueue(i);
    	// 处理文件事件	(文件事件分派器)
    	processFileEvent(fileEvent);
    }

}

void processFileEvent() {
	if event == '读事件' {
		// 读处理器
		processReadFile();
	}
	if event == '写事件' {
		// 写处理器
		processWriteFile();
	}
}

6.0 多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行
多线程步骤：
阶段一：服务端和客户端建立Socket连接，并分配处理线程
首先，主线程负责接收建立连接请求。当有客户端请求和实例建立Socket连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。
紧接着，主线程通过轮询方法把Socket连接分配给IO线程。

阶段二：IO线程读取并解析请求
主线程一旦把Socket分配给IO线程，就会进入阻塞状态，等待IO线程完成客户端请求读取和解析。因为有多个IO线程在并行处理，所以，这个过程很快就可以完成。

阶段三：主线程执行请求操作
等到IO线程解析完请求，主线程还是会以单线程的方式执行这些命令操作

阶段四：IO线程回写Socket和主线程清空全局队列
当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待IO线程，把这些结果回写到Socket中，并返回给客户端。
和IO线程读取和解析请求一样，IO线程回写Socket时，也是有多个线程在并发执行，所以回写Socket的速度也很快。等到IO线程回写Socket完毕，主线程会清空全局队列，等待客户端的后续请求。

6、redis持久化方式
RDB：全量持久化，指定时间间隔内对redis内存数据全量写入磁盘,二进制文件。
fork一个子进程去执行。快照的时候，不会把已过期的key持久化到RDB;bgsave
当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。写时复制
适合做备份，但是有数据丢失的风险
save 900 1
save 300 10
save 60 10000
AOF：增量持久化，以日志的形式记录服务器处理的增删改操作
appendonly yes
# appendfsync always    每次操作都会立即写入aof文件中
appendfsync everysec	每秒持久化一次(默认配置)
# appendfsync no		不主动进行同步操作，默认30s一次
最大可能保证数据不丢失

7.redis实现分布式锁要考虑那些问题
获得锁                 set key value ex 1000 nx  可以实现获取锁，锁超时自动释放
释放锁
超时的自动释放锁       set key value ex 1000 nx  可以实现获取锁，锁超时自动释放
未获得到锁的等待机制
锁超时的处理